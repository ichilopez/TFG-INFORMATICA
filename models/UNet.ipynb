{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f545ae07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'image_manager' from 'c:\\\\Users\\\\Itziar\\\\Documents\\\\Documentos\\\\TFG-INFORMATICA\\\\image_manager.py'>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import logging\n",
    "import os\n",
    "import sys\n",
    "import tempfile\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "import torch\n",
    "from PIL import Image\n",
    "from monai import config\n",
    "from monai.data import ArrayDataset, create_test_image_2d, decollate_batch, DataLoader\n",
    "from monai.inferers import sliding_window_inference\n",
    "from monai.metrics import DiceMetric\n",
    "from monai.networks.nets import UNet\n",
    "from monai.transforms import Activations, AsDiscrete, Compose, LoadImage, SaveImage, ScaleIntensity\n",
    "import importlib\n",
    "import image_manager\n",
    "importlib.reload(image_manager)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b7eeb54b",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_mass_test = 'C:/Users/Itziar/Documents/Documentos/TFG-INF-DATOS/archive/csv/mass_case_description_test_set.csv'\n",
    "path_mass_train = 'C:/Users/Itziar/Documents/Documentos/TFG-INF-DATOS/archive/csv/mass_case_description_train_set.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f0ad233",
   "metadata": {},
   "outputs": [],
   "source": [
    "mass_test_data = pd.read_csv(path_mass_test)\n",
    "mass_train_data = pd.read_csv(path_mass_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "94a71142",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images,train_segs,test_images,test_segs = image_manager.getSetImagesPaths(mass_test_data,mass_train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f435ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def main(train_images,trains_segs):\n",
    "    logging.basicConfig(stream=sys.stdout, level=logging.INFO) #Imprime la informaci칩n por consola\n",
    "    \n",
    "\n",
    "    # define transforms for image and segmentation\n",
    "    imtrans = Compose([LoadImage(image_only=True, ensure_channel_first=True), ScaleIntensity()])\n",
    "    segtrans = Compose([LoadImage(image_only=True, ensure_channel_first=True), ScaleIntensity()])\n",
    "    #En cada posisci칩n tendremos la tupla [imagen,segmentaci칩n]\n",
    "    val_ds = ArrayDataset(train_images, imtrans, trains_segs, segtrans)\n",
    "    # sliding window inference for one image at every iteration\n",
    "    val_loader = DataLoader(val_ds, batch_size=1, num_workers=1, pin_memory=torch.cuda.is_available())\n",
    "    dice_metric = DiceMetric(include_background=False, reduction=\"mean\", get_not_nans=False)\n",
    "    #Para convertir las probabilidades en m치scara binaria \n",
    "    post_trans = Compose([Activations(sigmoid=True), AsDiscrete(threshold=0.5)])\n",
    "    saver = SaveImage(output_dir=\"./output\", output_ext=\".png\", output_postfix=\"seg\", scale=255)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = UNet(\n",
    "        spatial_dims=2,\n",
    "        in_channels=1,\n",
    "        out_channels=1,\n",
    "        channels=(16, 32, 64, 128, 256),\n",
    "        strides=(2, 2, 2, 2),\n",
    "        num_res_units=2,\n",
    "    ).to(device)\n",
    "\n",
    "    model.load_state_dict(torch.load(\"best_metric_model_segmentation2d_array.pth\", weights_only=True))\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for val_data in val_loader:\n",
    "            val_images, val_labels = val_data[0].to(device), val_data[1].to(device)\n",
    "            # define sliding window size and batch size for windows inference\n",
    "            roi_size = (96, 96)\n",
    "            sw_batch_size = 4\n",
    "            val_outputs = sliding_window_inference(val_images, roi_size, sw_batch_size, model)\n",
    "            val_outputs = [post_trans(i) for i in decollate_batch(val_outputs)]\n",
    "            val_labels = decollate_batch(val_labels)\n",
    "            # compute metric for current iteration\n",
    "            dice_metric(y_pred=val_outputs, y=val_labels)\n",
    "            for val_output in val_outputs:\n",
    "                saver(val_output)\n",
    "        # aggregate the final mean dice result\n",
    "        print(\"evaluation metric:\", dice_metric.aggregate().item())\n",
    "        # reset the status\n",
    "        dice_metric.reset()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    with tempfile.TemporaryDirectory() as tempdir:\n",
    "        main(tempdir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TFG",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
